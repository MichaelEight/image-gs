{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Image-GS Quick Start\n\nMinimal setup for RTX 4090. Tested on runpod.io.\n\n## Usage\n1. Copy this notebook to your workspace (e.g., `/workspace/quick-start.ipynb`)\n2. Run all cells to install dependencies and clone repository\n3. Place images in `/workspace/input/`\n4. Configure and train!\n\n## Workspace Structure\n```\n/workspace/\n├── quick-start.ipynb  (this notebook)\n├── input/            (your images)\n├── output/           (results)\n└── image-gs/         (repository)\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Install System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing system dependencies...\\n\")\n",
    "\n",
    "commands = [\n",
    "    \"apt-get update -qq\",\n",
    "    \"apt-get install -y -qq build-essential git wget curl\",\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    subprocess.run(cmd, shell=True, capture_output=True)\n",
    "\n",
    "print(\"✓ System dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Install PyTorch (CUDA 12.1 for RTX 4090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing PyTorch 2.4.1 with CUDA 12.1...\\n\")\n",
    "\n",
    "!{sys.executable} -m pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "print(f\"\\n✓ PyTorch {torch.__version__}\")\n",
    "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"✓ GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing Python dependencies...\\n\")\n",
    "\n",
    "dependencies = [\n",
    "    \"flip-evaluator\",\n",
    "    \"lpips==0.1.4\",\n",
    "    \"matplotlib==3.9.2\",\n",
    "    \"numpy<2.1\",\n",
    "    \"opencv-python==4.12.0.88\",\n",
    "    \"pytorch-msssim==1.0.0\",\n",
    "    \"scikit-image==0.24.0\",\n",
    "    \"scipy==1.13.1\",\n",
    "    \"torchmetrics==1.5.2\",\n",
    "    \"jaxtyping\",\n",
    "    \"rich>=12\",\n",
    "    \"pyyaml==6.0\",\n",
    "    \"ninja\",\n",
    "]\n",
    "\n",
    "for dep in dependencies:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep, \"-q\"], capture_output=True)\n",
    "\n",
    "print(\"✓ Python dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Determine root workspace directory (where this notebook is located)\n# On runpod.io this would be /workspace\nROOT_WORKSPACE = os.getcwd()\n\n# Repository will be cloned here\nREPO_DIR = os.path.join(ROOT_WORKSPACE, \"image-gs\")\n\nif os.path.exists(REPO_DIR):\n    print(f\"Repository already exists at {REPO_DIR}\")\n    !cd {REPO_DIR} && git pull\nelse:\n    print(f\"Cloning repository to {REPO_DIR}...\\n\")\n    !git clone https://github.com/NYU-ICL/image-gs.git {REPO_DIR}\n\nprint(f\"\\n✓ Repository: {REPO_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Install fused-ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing fused-ssim...\\n\")\n",
    "\n",
    "!{sys.executable} -m pip install git+https://github.com/rahul-goel/fused-ssim.git --no-build-isolation -q\n",
    "\n",
    "print(\"✓ fused-ssim installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 7: Install gsplat (with fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Installing gsplat CUDA extension...\\n\")\nprint(\"This will take 5-10 minutes.\\n\")\n\ngsplat_dir = os.path.join(REPO_DIR, \"gsplat\")\nos.chdir(gsplat_dir)\n\n# Uninstall any existing installation\n!{sys.executable} -m pip uninstall -y gsplat -q\n!{sys.executable} -m pip cache purge -q\n\n# Regular install (not editable) - this is the fix from step 9\n!{sys.executable} -m pip install . --no-build-isolation\n\nprint(\"\\n✓ gsplat installed\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 8: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Verifying installation...\\n\")\n\n# Force reimport\nimport importlib\nfor mod in list(sys.modules.keys()):\n    if 'gsplat' in mod:\n        del sys.modules[mod]\n\nerrors = []\n\ntry:\n    import torch\n    assert torch.cuda.is_available()\n    print(\"✓ PyTorch with CUDA\")\nexcept Exception as e:\n    errors.append(f\"PyTorch: {e}\")\n\ntry:\n    from fused_ssim import fused_ssim\n    print(\"✓ fused_ssim\")\nexcept Exception as e:\n    errors.append(f\"fused_ssim: {e}\")\n\ntry:\n    from gsplat import (\n        project_gaussians_2d_scale_rot,\n        rasterize_gaussians_no_tiles,\n        rasterize_gaussians_sum,\n    )\n    print(\"✓ gsplat CUDA extensions\")\nexcept Exception as e:\n    errors.append(f\"gsplat: {e}\")\n\ntry:\n    os.chdir(REPO_DIR)\n    sys.path.insert(0, REPO_DIR)\n    from model import GaussianSplatting2D\n    from utils.misc_utils import load_cfg\n    print(\"✓ Image-GS modules\")\nexcept Exception as e:\n    errors.append(f\"Image-GS: {e}\")\n\nif errors:\n    print(f\"\\n⚠️  {len(errors)} error(s):\")\n    for err in errors:\n        print(f\"  {err}\")\nelse:\n    print(\"\\n✅ All components verified!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "## Step 9: Setup Workspace\n\nCreates organized directory structure for inputs and outputs."
  },
  {
   "cell_type": "code",
   "id": "4hyo8dhocfv",
   "source": "import glob\nimport shutil\nimport numpy as np\nfrom datetime import datetime\nfrom PIL import Image\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nmatplotlib.rcParams['text.usetex'] = False\n\n# Get paths from global variables (set in previous cells)\n# These will be set when Step 5 and Step 9 are run\ndef get_paths():\n    \"\"\"Get workspace paths, with fallback defaults. Create directories if needed.\"\"\"\n    global ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR\n    \n    if 'ROOT_WORKSPACE' not in globals():\n        ROOT_WORKSPACE = os.getcwd()\n    if 'REPO_DIR' not in globals():\n        REPO_DIR = os.path.join(ROOT_WORKSPACE, \"image-gs\")\n    if 'INPUT_DIR' not in globals():\n        INPUT_DIR = os.path.join(ROOT_WORKSPACE, \"input\")\n    if 'OUTPUT_DIR' not in globals():\n        OUTPUT_DIR = os.path.join(ROOT_WORKSPACE, \"output\")\n    \n    # Ensure input and output directories exist\n    os.makedirs(INPUT_DIR, exist_ok=True)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    \n    return ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR\n\n\ndef train_image_gs(input_filename, num_gaussians, max_steps, use_progressive=True):\n    \"\"\"\n    Train Image-GS model with organized file management.\n    \n    Args:\n        input_filename: Just the filename (e.g., \"cat.png\") from input/\n        num_gaussians: Number of Gaussians\n        max_steps: Training steps\n        use_progressive: Enable progressive optimization (default: True)\n    \n    Returns:\n        output_folder: Name of the created output folder\n    \"\"\"\n    # Get workspace paths\n    ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR = get_paths()\n    \n    # Change to repository directory for training\n    os.chdir(REPO_DIR)\n    \n    # Validate input\n    input_path = os.path.join(INPUT_DIR, input_filename)\n    if not os.path.exists(input_path):\n        raise FileNotFoundError(f\"Input image not found: {input_path}\")\n    \n    # Create timestamped output folder name\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    base_name = os.path.splitext(input_filename)[0]\n    output_folder = f\"{base_name}-{num_gaussians}-{max_steps}-{timestamp}\"\n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    os.makedirs(output_path, exist_ok=True)\n    os.makedirs(os.path.join(output_path, \"other\"), exist_ok=True)\n    \n    # Copy input to media/images/ (relative to repo)\n    media_input_path = os.path.join(REPO_DIR, \"media\", \"images\", input_filename)\n    os.makedirs(os.path.join(REPO_DIR, \"media\", \"images\"), exist_ok=True)\n    shutil.copy2(input_path, media_input_path)\n    \n    # Setup temporary experiment name\n    temp_exp_name = f\"temp/{output_folder}\"\n    \n    # Build command with optional progressive optimization flag\n    prog_flag = \"\" if use_progressive else \"--disable_prog_optim\"\n    \n    # Run training\n    cmd = f\"\"\"\n    {sys.executable} main.py \\\n      --input_path=\"images/{input_filename}\" \\\n      --exp_name=\"{temp_exp_name}\" \\\n      --num_gaussians={num_gaussians} \\\n      --max_steps={max_steps} \\\n      --quantize \\\n      {prog_flag} \\\n      --device=\"cuda:0\"\n    \"\"\"\n    \n    print(\"=\" * 80)\n    print(f\"🚀 TRAINING: {input_filename}\")\n    print(\"=\" * 80)\n    print(f\"Gaussians:   {num_gaussians}\")\n    print(f\"Steps:       {max_steps}\")\n    print(f\"Progressive: {use_progressive}\")\n    print(f\"Output:      output/{output_folder}/\")\n    print(f\"Time est:    ~{max_steps * 0.002:.1f}-{max_steps * 0.005:.1f} minutes\")\n    print(\"=\" * 80)\n    print()\n    \n    os.system(cmd)\n    \n    # Organize outputs\n    result_base = os.path.join(REPO_DIR, \"results\", temp_exp_name)\n    run_dirs = [d for d in os.listdir(result_base) if os.path.isdir(os.path.join(result_base, d))]\n    latest_run = sorted(run_dirs)[-1]\n    result_dir = os.path.join(result_base, latest_run)\n    \n    # Copy key files to output folder\n    # 1. Model checkpoint\n    ckpt_dir = os.path.join(result_dir, \"checkpoints\")\n    ckpt_files = glob.glob(os.path.join(ckpt_dir, \"ckpt_step-*.pt\"))\n    if ckpt_files:\n        latest_ckpt = sorted(ckpt_files)[-1]\n        shutil.copy2(latest_ckpt, os.path.join(output_path, \"model.pt\"))\n    \n    # 2. Rendered image\n    renders = glob.glob(os.path.join(result_dir, \"render_res-*.jpg\"))\n    if renders:\n        shutil.copy2(renders[0], os.path.join(output_path, \"rendered.jpg\"))\n    \n    # 3. Ground truth image\n    gts = glob.glob(os.path.join(result_dir, \"gt_res-*.jpg\"))\n    if gts:\n        shutil.copy2(gts[0], os.path.join(output_path, \"other\", \"ground_truth.jpg\"))\n    \n    # 4. Training log\n    log_file = os.path.join(result_dir, \"log_train.txt\")\n    if os.path.exists(log_file):\n        shutil.copy2(log_file, os.path.join(output_path, \"other\", \"log_train.txt\"))\n    \n    # 5. Copy all other files to \"other\" subdirectory\n    for item in os.listdir(result_dir):\n        item_path = os.path.join(result_dir, item)\n        if os.path.isfile(item_path):\n            # Skip files we already copied\n            if item not in [\"log_train.txt\"] and not item.startswith(\"render_res-\") and not item.startswith(\"gt_res-\"):\n                shutil.copy2(item_path, os.path.join(output_path, \"other\", item))\n    \n    print()\n    print(\"=\" * 80)\n    print(\"✅ TRAINING COMPLETE\")\n    print(\"=\" * 80)\n    print(f\"📁 Output folder: output/{output_folder}/\")\n    print()\n    \n    return output_folder\n\n\ndef view_results(output_folder):\n    \"\"\"\n    View and analyze results from a training run.\n    \n    Args:\n        output_folder: Name of folder in output/ (e.g., \"cat-10000-5000-20251027_143052\")\n    \"\"\"\n    # Get workspace paths\n    ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR = get_paths()\n    \n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    \n    if not os.path.exists(output_path):\n        raise FileNotFoundError(f\"Output folder not found: {output_path}\")\n    \n    # Load files\n    model_path = os.path.join(output_path, \"model.pt\")\n    rendered_path = os.path.join(output_path, \"rendered.jpg\")\n    gt_path = os.path.join(output_path, \"other\", \"ground_truth.jpg\")\n    \n    # Parse config from folder name\n    parts = output_folder.rsplit(\"-\", 3)\n    if len(parts) >= 3:\n        base_name = parts[0]\n        num_gaussians = int(parts[1])\n        max_steps = int(parts[2])\n    else:\n        base_name = output_folder\n        num_gaussians = \"?\"\n        max_steps = \"?\"\n    \n    # File sizes\n    model_size = os.path.getsize(model_path) if os.path.exists(model_path) else None\n    \n    # Load images\n    gt_img = np.array(Image.open(gt_path)).astype(np.float32) / 255.0\n    render_img = np.array(Image.open(rendered_path)).astype(np.float32) / 255.0\n    \n    # Calculate difference\n    diff = np.abs(gt_img - render_img)\n    diff_gray = np.mean(diff, axis=2)\n    \n    # Statistics\n    mean_diff = np.mean(diff_gray)\n    max_diff = np.max(diff_gray)\n    std_diff = np.std(diff_gray)\n    \n    # Image info\n    height, width, channels = gt_img.shape\n    total_pixels = width * height\n    gt_size = os.path.getsize(gt_path)\n    render_size = os.path.getsize(rendered_path)\n    \n    # Visualize\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    \n    axes[0].imshow(gt_img)\n    axes[0].set_title(\"Ground Truth\", fontsize=14, fontweight='bold')\n    axes[0].axis('off')\n    \n    axes[1].imshow(render_img)\n    axes[1].set_title(\"2D Gaussians (Rendered)\", fontsize=14, fontweight='bold')\n    axes[1].axis('off')\n    \n    im = axes[2].imshow(diff_gray, cmap='hot', vmin=0, vmax=0.2)\n    axes[2].set_title(f\"Difference Map\\nMean: {mean_diff:.4f} ({mean_diff*100:.2f}%)\", fontsize=14, fontweight='bold')\n    axes[2].axis('off')\n    \n    cbar = plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n    cbar.set_label('Absolute Difference', rotation=270, labelpad=20)\n    \n    plt.tight_layout()\n    \n    # Save visualization\n    summary_img_path = os.path.join(output_path, \"summary.png\")\n    plt.savefig(summary_img_path, dpi=150, bbox_inches='tight')\n    \n    plt.show()\n    \n    # Format helpers\n    def fmt_size(size_bytes):\n        if size_bytes is None:\n            return \"N/A\"\n        if size_bytes < 1024:\n            return f\"{size_bytes} B\"\n        elif size_bytes < 1024 * 1024:\n            return f\"{size_bytes / 1024:.2f} KB\"\n        else:\n            return f\"{size_bytes / (1024 * 1024):.2f} MB\"\n    \n    def fmt_ratio(num, denom):\n        if num is None or denom is None:\n            return \"N/A\"\n        return f\"{num / denom:.2f}x\"\n    \n    # Build summary text with tables\n    summary_lines = []\n    summary_lines.append(\"=\" * 100)\n    summary_lines.append(\"IMAGE-GS TRAINING SUMMARY\")\n    summary_lines.append(\"=\" * 100)\n    summary_lines.append(\"\")\n    \n    # Table 1: Training Configuration\n    summary_lines.append(\"TRAINING CONFIGURATION\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Output Folder':<25} {'Base Name':<20} {'Gaussians':<15} {'Steps':<15}\")\n    summary_lines.append(f\"{output_folder:<25} {base_name:<20} {num_gaussians:<15} {max_steps:<15}\")\n    summary_lines.append(\"\")\n    \n    # Table 2: Image & File Information\n    summary_lines.append(\"IMAGE & FILE INFORMATION\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Metric':<30} {'Value':<30} {'Metric':<30} {'Value':<30}\")\n    summary_lines.append(f\"{'Resolution':<30} {f'{width} x {height} px':<30} {'Total Pixels':<30} {f'{total_pixels:,}':<30}\")\n    summary_lines.append(f\"{'Channels':<30} {channels:<30} {'Ground Truth Size':<30} {fmt_size(gt_size):<30}\")\n    summary_lines.append(f\"{'Model Size':<30} {fmt_size(model_size):<30} {'Rendered Size':<30} {fmt_size(render_size):<30}\")\n    summary_lines.append(\"\")\n    \n    # Table 3: Compression Analysis\n    if model_size:\n        uncompressed_size = total_pixels * channels\n        bpp = (model_size * 8) / total_pixels\n        compression_vs_gt = gt_size / model_size\n        compression_vs_raw = uncompressed_size / model_size\n        \n        summary_lines.append(\"COMPRESSION ANALYSIS\")\n        summary_lines.append(\"-\" * 100)\n        summary_lines.append(f\"{'Metric':<40} {'Value':<30} {'Note':<30}\")\n        summary_lines.append(f\"{'Compression vs Original (JPG)':<40} {fmt_ratio(gt_size, model_size):<30} {'Model is {:.1f}% of original'.format((model_size/gt_size)*100):<30}\")\n        summary_lines.append(f\"{'Compression vs Raw (uncompressed)':<40} {fmt_ratio(uncompressed_size, model_size):<30} {f'{fmt_size(uncompressed_size)} -> {fmt_size(model_size)}':<30}\")\n        summary_lines.append(f\"{'Bits Per Pixel (bpp)':<40} {f'{bpp:.4f} bpp':<30} {'Lower is better':<30}\")\n        summary_lines.append(\"\")\n    \n    # Table 4: Quality Metrics\n    pix_1pct = np.sum(diff_gray > 0.01) / diff_gray.size * 100\n    pix_5pct = np.sum(diff_gray > 0.05) / diff_gray.size * 100\n    pix_10pct = np.sum(diff_gray > 0.10) / diff_gray.size * 100\n    \n    summary_lines.append(\"QUALITY METRICS\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Metric':<30} {'Value':<30} {'Metric':<30} {'Value':<30}\")\n    summary_lines.append(f\"{'Mean Difference':<30} {f'{mean_diff:.6f} ({mean_diff*100:.2f}%)':<30} {'Max Difference':<30} {f'{max_diff:.6f} ({max_diff*100:.2f}%)':<30}\")\n    summary_lines.append(f\"{'Std Deviation':<30} {f'{std_diff:.6f}':<30} {'Pixels > 1% diff':<30} {f'{pix_1pct:.2f}%':<30}\")\n    summary_lines.append(f\"{'Pixels > 5% diff':<30} {f'{pix_5pct:.2f}%':<30} {'Pixels > 10% diff':<30} {f'{pix_10pct:.2f}%':<30}\")\n    summary_lines.append(\"\")\n    \n    # Files saved\n    summary_lines.append(\"FILES SAVED\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'File':<25} {'Description':<75}\")\n    summary_lines.append(f\"{'📄 summary.txt':<25} {'This summary (text format)':<75}\")\n    summary_lines.append(f\"{'📊 summary.png':<25} {'Visual comparison (3-panel image)':<75}\")\n    summary_lines.append(f\"{'🧠 model.pt':<25} {'Trained 2D Gaussian model (PyTorch checkpoint)':<75}\")\n    summary_lines.append(f\"{'🖼️  rendered.jpg':<25} {'Rendered output from model':<75}\")\n    summary_lines.append(f\"{'📁 other/':<25} {'Training logs and additional files':<75}\")\n    summary_lines.append(\"=\" * 100)\n    \n    summary_text = \"\\n\".join(summary_lines)\n    print(summary_text)\n    \n    # Save summary text\n    summary_txt_path = os.path.join(output_path, \"summary.txt\")\n    with open(summary_txt_path, 'w') as f:\n        f.write(summary_text)\n    \n    print()\n    print(f\"💾 Saved: summary.txt\")\n    print(f\"💾 Saved: summary.png\")\n    print()\n    print(f\"📁 Full path: {output_path}\")\n\n\ndef upscale_render(output_folder, render_height):\n    \"\"\"\n    Render at higher resolution using trained model.\n    \n    Args:\n        output_folder: Name of folder in output/ with trained model\n        render_height: Target height in pixels\n    \"\"\"\n    # Get workspace paths\n    ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR = get_paths()\n    \n    # Change to repository directory\n    os.chdir(REPO_DIR)\n    \n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    if not os.path.exists(output_path):\n        raise FileNotFoundError(f\"Output folder not found: {output_path}\")\n    \n    # Parse config from folder name\n    parts = output_folder.rsplit(\"-\", 3)\n    base_name = parts[0]\n    num_gaussians = int(parts[1])\n    timestamp = parts[3]\n    \n    # Find original input file\n    input_files = glob.glob(os.path.join(INPUT_DIR, f\"{base_name}.*\"))\n    if not input_files:\n        raise FileNotFoundError(f\"Original input not found for: {base_name}\")\n    input_filename = os.path.basename(input_files[0])\n    \n    # Ensure input is in media/images/\n    media_input_path = os.path.join(REPO_DIR, \"media\", \"images\", input_filename)\n    if not os.path.exists(media_input_path):\n        shutil.copy2(input_files[0], media_input_path)\n    \n    # Setup experiment name (should match training)\n    temp_exp_name = f\"temp/{output_folder}\"\n    \n    # Run upscale render\n    cmd = f\"\"\"\n    {sys.executable} main.py \\\n      --input_path=\"images/{input_filename}\" \\\n      --exp_name=\"{temp_exp_name}\" \\\n      --num_gaussians={num_gaussians} \\\n      --quantize \\\n      --eval \\\n      --render_height={render_height} \\\n      --device=\"cuda:0\"\n    \"\"\"\n    \n    print(\"=\" * 80)\n    print(f\"🔍 UPSCALE RENDER: {output_folder}\")\n    print(\"=\" * 80)\n    print(f\"Target height: {render_height}px\")\n    print(\"=\" * 80)\n    print()\n    \n    os.system(cmd)\n    \n    # Find and copy upscaled render\n    result_base = os.path.join(REPO_DIR, \"results\", temp_exp_name)\n    run_dirs = [d for d in os.listdir(result_base) if os.path.isdir(os.path.join(result_base, d))]\n    latest_run = sorted(run_dirs)[-1]\n    eval_dir = os.path.join(result_base, latest_run, \"eval\")\n    \n    if os.path.exists(eval_dir):\n        upscaled_renders = glob.glob(os.path.join(eval_dir, \"render_*.jpg\"))\n        if upscaled_renders:\n            upscaled_name = f\"rendered_{render_height}px.jpg\"\n            shutil.copy2(upscaled_renders[0], os.path.join(output_path, upscaled_name))\n            print()\n            print(\"=\" * 80)\n            print(\"✅ UPSCALE COMPLETE\")\n            print(\"=\" * 80)\n            print(f\"💾 Saved: {upscaled_name}\")\n            print(f\"📁 Location: output/{output_folder}/\")\n            print(\"=\" * 80)\n        else:\n            print(\"⚠️  Warning: Could not find upscaled render\")\n    else:\n        print(\"⚠️  Warning: Eval directory not found\")\n\nprint(\"✅ Functions loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hccvnopc4dh",
   "source": "## Step 11: Configuration\n\nSet your input image and training parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "# Place your input image in: /workspace/input/\n# Example: /workspace/input/cat.png\n\nINPUT_FILENAME = \"cat.png\"  # Just the filename from input/\n\n# Training parameters\nNUM_GAUSSIANS = 10000       # More = better quality (5k-30k recommended)\nMAX_STEPS = 5000            # More = better convergence (3k-10k recommended)\nUSE_PROGRESSIVE = True      # Enable progressive optimization (recommended)\n\nprint(\"=\" * 80)\nprint(\"CONFIGURATION\")\nprint(\"=\" * 80)\nprint(f\"Input:       {os.path.join(ROOT_WORKSPACE, 'input', INPUT_FILENAME)}\")\nprint(f\"Output:      {os.path.join(ROOT_WORKSPACE, 'output')}/{INPUT_FILENAME.split('.')[0]}-{NUM_GAUSSIANS}-{MAX_STEPS}-[timestamp]/\")\nprint(f\"Gaussians:   {NUM_GAUSSIANS}\")\nprint(f\"Steps:       {MAX_STEPS}\")\nprint(f\"Progressive: {USE_PROGRESSIVE}\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": "## Step 12: Training\n\nTrain the model and save to organized output folder."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "output_folder = train_image_gs(\n    input_filename=INPUT_FILENAME,\n    num_gaussians=NUM_GAUSSIANS,\n    max_steps=MAX_STEPS,\n    use_progressive=USE_PROGRESSIVE\n)\n\nprint(f\"✅ Training complete!\")\nprint(f\"📁 Output: {os.path.join(ROOT_WORKSPACE, 'output', output_folder)}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": "## Step 13: View Results\n\nDisplay comparison visualization and save summary files."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# Use the output_folder from training\nview_results(output_folder)\n\n# Or manually specify a folder:\n# view_results(\"cat-10000-5000-20251027_143052\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": "## Step 14: Optional - Upscale Render\n\nRender at higher resolution using the trained model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Render at 2x resolution\n# upscale_render(\n#     output_folder=output_folder,  # or specify manually: \"cat-10000-5000-20251027_143052\"\n#     render_height=1024\n# )"
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Optional: Upscale Render\n",
    "\n",
    "Render at higher resolution using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Render at 2x resolution\n",
    "# upscale_render(\n",
    "#     input_image=INPUT_IMAGE,\n",
    "#     exp_name=EXP_NAME,\n",
    "#     num_gaussians=NUM_GAUSSIANS,\n",
    "#     render_height=1024  # Adjust as needed\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}