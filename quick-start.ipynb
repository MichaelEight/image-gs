{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Image-GS Quick Start\n\nMinimal setup for RTX 4090. Tested on runpod.io.\n\n## Usage\n1. Copy this notebook to your workspace (e.g., `/workspace/quick-start.ipynb`)\n2. Run all cells to install dependencies and clone repository\n3. Place images in `/workspace/input/`\n4. Configure and train!\n\n## Workspace Structure\n```\n/workspace/\n‚îú‚îÄ‚îÄ quick-start.ipynb  (this notebook)\n‚îú‚îÄ‚îÄ input/            (your images)\n‚îú‚îÄ‚îÄ output/           (results)\n‚îî‚îÄ‚îÄ image-gs/         (repository)\n```"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Step 1: Install System Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"Installing system dependencies...\\n\")\n",
    "\n",
    "commands = [\n",
    "    \"apt-get update -qq\",\n",
    "    \"apt-get install -y -qq build-essential git wget curl\",\n",
    "]\n",
    "\n",
    "for cmd in commands:\n",
    "    subprocess.run(cmd, shell=True, capture_output=True)\n",
    "\n",
    "print(\"‚úì System dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 2: Upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade pip setuptools wheel -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 3: Install PyTorch (CUDA 12.1 for RTX 4090)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing PyTorch 2.4.1 with CUDA 12.1...\\n\")\n",
    "\n",
    "!{sys.executable} -m pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úì PyTorch {torch.__version__}\")\n",
    "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 4: Install Python Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing Python dependencies...\\n\")\n",
    "\n",
    "dependencies = [\n",
    "    \"flip-evaluator\",\n",
    "    \"lpips==0.1.4\",\n",
    "    \"matplotlib==3.9.2\",\n",
    "    \"numpy<2.1\",\n",
    "    \"opencv-python==4.12.0.88\",\n",
    "    \"pytorch-msssim==1.0.0\",\n",
    "    \"scikit-image==0.24.0\",\n",
    "    \"scipy==1.13.1\",\n",
    "    \"torchmetrics==1.5.2\",\n",
    "    \"jaxtyping\",\n",
    "    \"rich>=12\",\n",
    "    \"pyyaml==6.0\",\n",
    "    \"ninja\",\n",
    "]\n",
    "\n",
    "for dep in dependencies:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", dep, \"-q\"], capture_output=True)\n",
    "\n",
    "print(\"‚úì Python dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 5: Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# Determine root workspace directory (where this notebook is located)\n# On runpod.io this would be /workspace\nROOT_WORKSPACE = os.getcwd()\n\n# Repository will be cloned here\nREPO_DIR = os.path.join(ROOT_WORKSPACE, \"image-gs\")\n\nif os.path.exists(REPO_DIR):\n    print(f\"Repository already exists at {REPO_DIR}\")\n    !cd {REPO_DIR} && git pull\nelse:\n    print(f\"Cloning repository to {REPO_DIR}...\\n\")\n    !git clone https://github.com/NYU-ICL/image-gs.git {REPO_DIR}\n\nprint(f\"\\n‚úì Repository: {REPO_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 6: Install fused-ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Installing fused-ssim...\\n\")\n",
    "\n",
    "!{sys.executable} -m pip install git+https://github.com/rahul-goel/fused-ssim.git --no-build-isolation -q\n",
    "\n",
    "print(\"‚úì fused-ssim installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 7: Install gsplat (with fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Installing gsplat CUDA extension...\\n\")\nprint(\"This will take 5-10 minutes.\\n\")\n\ngsplat_dir = os.path.join(REPO_DIR, \"gsplat\")\nos.chdir(gsplat_dir)\n\n# Uninstall any existing installation\n!{sys.executable} -m pip uninstall -y gsplat -q\n!{sys.executable} -m pip cache purge -q\n\n# Regular install (not editable) - this is the fix from step 9\n!{sys.executable} -m pip install . --no-build-isolation\n\nprint(\"\\n‚úì gsplat installed\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 8: Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "print(\"Verifying installation...\\n\")\n\n# Force reimport\nimport importlib\nfor mod in list(sys.modules.keys()):\n    if 'gsplat' in mod:\n        del sys.modules[mod]\n\nerrors = []\n\ntry:\n    import torch\n    assert torch.cuda.is_available()\n    print(\"‚úì PyTorch with CUDA\")\nexcept Exception as e:\n    errors.append(f\"PyTorch: {e}\")\n\ntry:\n    from fused_ssim import fused_ssim\n    print(\"‚úì fused_ssim\")\nexcept Exception as e:\n    errors.append(f\"fused_ssim: {e}\")\n\ntry:\n    from gsplat import (\n        project_gaussians_2d_scale_rot,\n        rasterize_gaussians_no_tiles,\n        rasterize_gaussians_sum,\n    )\n    print(\"‚úì gsplat CUDA extensions\")\nexcept Exception as e:\n    errors.append(f\"gsplat: {e}\")\n\ntry:\n    os.chdir(REPO_DIR)\n    sys.path.insert(0, REPO_DIR)\n    from model import GaussianSplatting2D\n    from utils.misc_utils import load_cfg\n    print(\"‚úì Image-GS modules\")\nexcept Exception as e:\n    errors.append(f\"Image-GS: {e}\")\n\nif errors:\n    print(f\"\\n‚ö†Ô∏è  {len(errors)} error(s):\")\n    for err in errors:\n        print(f\"  {err}\")\nelse:\n    print(\"\\n‚úÖ All components verified!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": "## Step 9: Setup Workspace\n\nCreates organized directory structure for inputs and outputs."
  },
  {
   "cell_type": "code",
   "id": "4hyo8dhocfv",
   "source": "import glob\nimport shutil\nimport numpy as np\nfrom datetime import datetime\nfrom PIL import Image\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nmatplotlib.rcParams['text.usetex'] = False\n\n# Create workspace structure at root level\nINPUT_DIR = os.path.join(ROOT_WORKSPACE, \"input\")\nOUTPUT_DIR = os.path.join(ROOT_WORKSPACE, \"output\")\n\nos.makedirs(INPUT_DIR, exist_ok=True)\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(\"‚úÖ Workspace structure created:\")\nprint(f\"   üìÅ {ROOT_WORKSPACE}/\")\nprint(f\"      ‚îú‚îÄ‚îÄ quick-start.ipynb\")\nprint(f\"      ‚îú‚îÄ‚îÄ input/   (place your images here)\")\nprint(f\"      ‚îú‚îÄ‚îÄ output/  (results will be saved here)\")\nprint(f\"      ‚îî‚îÄ‚îÄ image-gs/  (repository)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "k33fs82mxp",
   "source": "## Step 10: Function Definitions\n\nHelper functions for training, viewing, and analyzing results.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "mnm2y26mz1t",
   "source": "def get_paths():\n    \"\"\"Get workspace paths, with fallback defaults. Create directories if needed.\"\"\"\n    global ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR\n    \n    if 'ROOT_WORKSPACE' not in globals():\n        ROOT_WORKSPACE = os.getcwd()\n    if 'REPO_DIR' not in globals():\n        REPO_DIR = os.path.join(ROOT_WORKSPACE, \"image-gs\")\n    if 'INPUT_DIR' not in globals():\n        INPUT_DIR = os.path.join(ROOT_WORKSPACE, \"input\")\n    if 'OUTPUT_DIR' not in globals():\n        OUTPUT_DIR = os.path.join(ROOT_WORKSPACE, \"output\")\n    \n    # Ensure input and output directories exist\n    os.makedirs(INPUT_DIR, exist_ok=True)\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    \n    return ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yqr4h8o60bd",
   "source": "def _setup_training_environment(input_filename, num_gaussians, max_steps):\n    \"\"\"Setup training environment: validate input, create directories, copy files.\"\"\"\n    ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR = get_paths()\n    \n    # Change to repository directory\n    os.chdir(REPO_DIR)\n    \n    # Validate input\n    input_path = os.path.join(INPUT_DIR, input_filename)\n    if not os.path.exists(input_path):\n        raise FileNotFoundError(f\"Input image not found: {input_path}\")\n    \n    # Create timestamped output folder\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    base_name = os.path.splitext(input_filename)[0]\n    output_folder = f\"{base_name}-{num_gaussians}-{max_steps}-{timestamp}\"\n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    \n    os.makedirs(output_path, exist_ok=True)\n    os.makedirs(os.path.join(output_path, \"other\"), exist_ok=True)\n    \n    # Copy input to media/images/\n    media_input_path = os.path.join(REPO_DIR, \"media\", \"images\", input_filename)\n    os.makedirs(os.path.join(REPO_DIR, \"media\", \"images\"), exist_ok=True)\n    shutil.copy2(input_path, media_input_path)\n    \n    return output_folder, output_path",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "vn2z6up54oh",
   "source": "def _build_training_command(input_filename, output_folder, num_gaussians, max_steps, use_progressive):\n    \"\"\"Build the training command string.\"\"\"\n    prog_flag = \"\" if use_progressive else \"--disable_prog_optim\"\n    temp_exp_name = f\"temp/{output_folder}\"\n    \n    cmd = f\"\"\"\n    {sys.executable} main.py \\\n      --input_path=\"images/{input_filename}\" \\\n      --exp_name=\"{temp_exp_name}\" \\\n      --num_gaussians={num_gaussians} \\\n      --max_steps={max_steps} \\\n      --quantize \\\n      {prog_flag} \\\n      --device=\"cuda:0\"\n    \"\"\"\n    \n    return cmd",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b4hlioj54u8",
   "source": "def _run_training(cmd, input_filename, num_gaussians, max_steps, use_progressive, output_folder):\n    \"\"\"Print training info and execute training command.\"\"\"\n    ROOT_WORKSPACE, _, _, _ = get_paths()\n    \n    print(\"=\" * 80)\n    print(f\"üöÄ TRAINING: {input_filename}\")\n    print(\"=\" * 80)\n    print(f\"Gaussians:   {num_gaussians}\")\n    print(f\"Steps:       {max_steps}\")\n    print(f\"Progressive: {use_progressive}\")\n    print(f\"Output:      output/{output_folder}/\")\n    print(f\"Time est:    ~{max_steps * 0.002:.1f}-{max_steps * 0.005:.1f} minutes\")\n    print(\"=\" * 80)\n    print()\n    \n    os.system(cmd)\n    \n    print()\n    print(\"=\" * 80)\n    print(\"‚úÖ TRAINING COMPLETE\")\n    print(\"=\" * 80)\n    print(f\"üìÅ Output folder: output/{output_folder}/\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ykwnco783bq",
   "source": "def _organize_training_outputs(output_folder, output_path):\n    \"\"\"Copy training outputs to organized output folder.\"\"\"\n    _, REPO_DIR, _, _ = get_paths()\n    \n    temp_exp_name = f\"temp/{output_folder}\"\n    result_base = os.path.join(REPO_DIR, \"results\", temp_exp_name)\n    run_dirs = [d for d in os.listdir(result_base) if os.path.isdir(os.path.join(result_base, d))]\n    latest_run = sorted(run_dirs)[-1]\n    result_dir = os.path.join(result_base, latest_run)\n    \n    # 1. Model checkpoint\n    ckpt_dir = os.path.join(result_dir, \"checkpoints\")\n    ckpt_files = glob.glob(os.path.join(ckpt_dir, \"ckpt_step-*.pt\"))\n    if ckpt_files:\n        latest_ckpt = sorted(ckpt_files)[-1]\n        shutil.copy2(latest_ckpt, os.path.join(output_path, \"model.pt\"))\n    \n    # 2. Rendered image\n    renders = glob.glob(os.path.join(result_dir, \"render_res-*.jpg\"))\n    if renders:\n        shutil.copy2(renders[0], os.path.join(output_path, \"rendered.jpg\"))\n    \n    # 3. Ground truth image\n    gts = glob.glob(os.path.join(result_dir, \"gt_res-*.jpg\"))\n    if gts:\n        shutil.copy2(gts[0], os.path.join(output_path, \"other\", \"ground_truth.jpg\"))\n    \n    # 4. Training log\n    log_file = os.path.join(result_dir, \"log_train.txt\")\n    if os.path.exists(log_file):\n        shutil.copy2(log_file, os.path.join(output_path, \"other\", \"log_train.txt\"))\n    \n    # 5. Metrics CSV\n    metrics_csv = os.path.join(result_dir, \"metrics.csv\")\n    if os.path.exists(metrics_csv):\n        shutil.copy2(metrics_csv, os.path.join(output_path, \"metrics.csv\"))\n    \n    # 6. Copy all other files to \"other\" subdirectory\n    for item in os.listdir(result_dir):\n        item_path = os.path.join(result_dir, item)\n        if os.path.isfile(item_path):\n            # Skip files we already copied\n            if item not in [\"log_train.txt\", \"metrics.csv\"] and not item.startswith(\"render_res-\") and not item.startswith(\"gt_res-\"):\n                shutil.copy2(item_path, os.path.join(output_path, \"other\", item))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bst5yynyf9",
   "source": "def train_image_gs(input_filename, num_gaussians, max_steps, use_progressive=True):\n    \"\"\"\n    Train Image-GS model with organized file management.\n    \n    Args:\n        input_filename: Just the filename (e.g., \"cat.png\") from input/\n        num_gaussians: Number of Gaussians\n        max_steps: Training steps\n        use_progressive: Enable progressive optimization (default: True)\n    \n    Returns:\n        output_folder: Name of the created output folder\n    \"\"\"\n    output_folder, output_path = _setup_training_environment(input_filename, num_gaussians, max_steps)\n    cmd = _build_training_command(input_filename, output_folder, num_gaussians, max_steps, use_progressive)\n    _run_training(cmd, input_filename, num_gaussians, max_steps, use_progressive, output_folder)\n    _organize_training_outputs(output_folder, output_path)\n    \n    return output_folder",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hlgla25hcn",
   "source": "def _load_training_results(output_folder):\n    \"\"\"Load training results and parse configuration.\"\"\"\n    _, _, _, OUTPUT_DIR = get_paths()\n    \n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    if not os.path.exists(output_path):\n        raise FileNotFoundError(f\"Output folder not found: {output_path}\")\n    \n    # Parse config from folder name\n    parts = output_folder.rsplit(\"-\", 3)\n    if len(parts) >= 3:\n        base_name = parts[0]\n        num_gaussians = int(parts[1])\n        max_steps = int(parts[2])\n    else:\n        base_name = output_folder\n        num_gaussians = \"?\"\n        max_steps = \"?\"\n    \n    # File paths\n    model_path = os.path.join(output_path, \"model.pt\")\n    rendered_path = os.path.join(output_path, \"rendered.jpg\")\n    gt_path = os.path.join(output_path, \"other\", \"ground_truth.jpg\")\n    \n    # Load images\n    gt_img = np.array(Image.open(gt_path)).astype(np.float32) / 255.0\n    render_img = np.array(Image.open(rendered_path)).astype(np.float32) / 255.0\n    \n    # File sizes\n    model_size = os.path.getsize(model_path) if os.path.exists(model_path) else None\n    gt_size = os.path.getsize(gt_path)\n    render_size = os.path.getsize(rendered_path)\n    \n    return {\n        'output_path': output_path,\n        'output_folder': output_folder,\n        'base_name': base_name,\n        'num_gaussians': num_gaussians,\n        'max_steps': max_steps,\n        'gt_img': gt_img,\n        'render_img': render_img,\n        'model_size': model_size,\n        'gt_size': gt_size,\n        'render_size': render_size\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b1w1sbsqi5e",
   "source": "def _calculate_quality_metrics(gt_img, render_img):\n    \"\"\"Calculate quality metrics between ground truth and rendered images.\"\"\"\n    # Calculate difference\n    diff = np.abs(gt_img - render_img)\n    diff_gray = np.mean(diff, axis=2)\n    \n    # Basic statistics\n    mean_diff = np.mean(diff_gray)\n    max_diff = np.max(diff_gray)\n    std_diff = np.std(diff_gray)\n    \n    # Pixel-level analysis\n    pix_1pct = np.sum(diff_gray > 0.01) / diff_gray.size * 100\n    pix_5pct = np.sum(diff_gray > 0.05) / diff_gray.size * 100\n    pix_10pct = np.sum(diff_gray > 0.10) / diff_gray.size * 100\n    \n    return {\n        'diff': diff,\n        'diff_gray': diff_gray,\n        'mean_diff': mean_diff,\n        'max_diff': max_diff,\n        'std_diff': std_diff,\n        'pix_1pct': pix_1pct,\n        'pix_5pct': pix_5pct,\n        'pix_10pct': pix_10pct\n    }",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ox8rehpjkmc",
   "source": "def _create_results_visualization(gt_img, render_img, diff_gray, mean_diff):\n    \"\"\"Create 3-panel comparison visualization.\"\"\"\n    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n    \n    axes[0].imshow(gt_img)\n    axes[0].set_title(\"Ground Truth\", fontsize=14, fontweight='bold')\n    axes[0].axis('off')\n    \n    axes[1].imshow(render_img)\n    axes[1].set_title(\"2D Gaussians (Rendered)\", fontsize=14, fontweight='bold')\n    axes[1].axis('off')\n    \n    im = axes[2].imshow(diff_gray, cmap='hot', vmin=0, vmax=0.2)\n    axes[2].set_title(f\"Difference Map\\nMean: {mean_diff:.4f} ({mean_diff*100:.2f}%)\", fontsize=14, fontweight='bold')\n    axes[2].axis('off')\n    \n    cbar = plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n    cbar.set_label('Absolute Difference', rotation=270, labelpad=20)\n    \n    plt.tight_layout()\n    \n    return fig",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "m42vnc3bzmm",
   "source": "def _format_summary_text(results_data, metrics_data):\n    \"\"\"Format summary text with tables.\"\"\"\n    # Helper functions\n    def fmt_size(size_bytes):\n        if size_bytes is None:\n            return \"N/A\"\n        if size_bytes < 1024:\n            return f\"{size_bytes} B\"\n        elif size_bytes < 1024 * 1024:\n            return f\"{size_bytes / 1024:.2f} KB\"\n        else:\n            return f\"{size_bytes / (1024 * 1024):.2f} MB\"\n    \n    def fmt_ratio(num, denom):\n        if num is None or denom is None:\n            return \"N/A\"\n        return f\"{num / denom:.2f}x\"\n    \n    # Extract data\n    output_folder = results_data['output_folder']\n    base_name = results_data['base_name']\n    num_gaussians = results_data['num_gaussians']\n    max_steps = results_data['max_steps']\n    gt_img = results_data['gt_img']\n    model_size = results_data['model_size']\n    gt_size = results_data['gt_size']\n    render_size = results_data['render_size']\n    \n    mean_diff = metrics_data['mean_diff']\n    max_diff = metrics_data['max_diff']\n    std_diff = metrics_data['std_diff']\n    pix_1pct = metrics_data['pix_1pct']\n    pix_5pct = metrics_data['pix_5pct']\n    pix_10pct = metrics_data['pix_10pct']\n    \n    # Image info\n    height, width, channels = gt_img.shape\n    total_pixels = width * height\n    \n    # Build summary\n    summary_lines = []\n    summary_lines.append(\"=\" * 100)\n    summary_lines.append(\"IMAGE-GS TRAINING SUMMARY\")\n    summary_lines.append(\"=\" * 100)\n    summary_lines.append(\"\")\n    \n    # Table 1: Training Configuration\n    summary_lines.append(\"TRAINING CONFIGURATION\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Output Folder':<25} {'Base Name':<20} {'Gaussians':<15} {'Steps':<15}\")\n    summary_lines.append(f\"{output_folder:<25} {base_name:<20} {num_gaussians:<15} {max_steps:<15}\")\n    summary_lines.append(\"\")\n    \n    # Table 2: Image & File Information\n    summary_lines.append(\"IMAGE & FILE INFORMATION\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Metric':<30} {'Value':<30} {'Metric':<30} {'Value':<30}\")\n    summary_lines.append(f\"{'Resolution':<30} {f'{width} x {height} px':<30} {'Total Pixels':<30} {f'{total_pixels:,}':<30}\")\n    summary_lines.append(f\"{'Channels':<30} {channels:<30} {'Ground Truth Size':<30} {fmt_size(gt_size):<30}\")\n    summary_lines.append(f\"{'Model Size':<30} {fmt_size(model_size):<30} {'Rendered Size':<30} {fmt_size(render_size):<30}\")\n    summary_lines.append(\"\")\n    \n    # Table 3: Compression Analysis\n    if model_size:\n        uncompressed_size = total_pixels * channels\n        bpp = (model_size * 8) / total_pixels\n        compression_vs_gt = gt_size / model_size\n        compression_vs_raw = uncompressed_size / model_size\n        \n        summary_lines.append(\"COMPRESSION ANALYSIS\")\n        summary_lines.append(\"-\" * 100)\n        summary_lines.append(f\"{'Metric':<40} {'Value':<30} {'Note':<30}\")\n        summary_lines.append(f\"{'Compression vs Original (JPG)':<40} {fmt_ratio(gt_size, model_size):<30} {'Model is {:.1f}% of original'.format((model_size/gt_size)*100):<30}\")\n        summary_lines.append(f\"{'Compression vs Raw (uncompressed)':<40} {fmt_ratio(uncompressed_size, model_size):<30} {f'{fmt_size(uncompressed_size)} -> {fmt_size(model_size)}':<30}\")\n        summary_lines.append(f\"{'Bits Per Pixel (bpp)':<40} {f'{bpp:.4f} bpp':<30} {'Lower is better':<30}\")\n        summary_lines.append(\"\")\n    \n    # Table 4: Quality Metrics\n    summary_lines.append(\"QUALITY METRICS\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'Metric':<30} {'Value':<30} {'Metric':<30} {'Value':<30}\")\n    summary_lines.append(f\"{'Mean Difference':<30} {f'{mean_diff:.6f} ({mean_diff*100:.2f}%)':<30} {'Max Difference':<30} {f'{max_diff:.6f} ({max_diff*100:.2f}%)':<30}\")\n    summary_lines.append(f\"{'Std Deviation':<30} {f'{std_diff:.6f}':<30} {'Pixels > 1% diff':<30} {f'{pix_1pct:.2f}%':<30}\")\n    summary_lines.append(f\"{'Pixels > 5% diff':<30} {f'{pix_5pct:.2f}%':<30} {'Pixels > 10% diff':<30} {f'{pix_10pct:.2f}%':<30}\")\n    summary_lines.append(\"\")\n    \n    # Files saved\n    summary_lines.append(\"FILES SAVED\")\n    summary_lines.append(\"-\" * 100)\n    summary_lines.append(f\"{'File':<25} {'Description':<75}\")\n    summary_lines.append(f\"{'üìÑ summary.txt':<25} {'This summary (text format)':<75}\")\n    summary_lines.append(f\"{'üìä summary.png':<25} {'Visual comparison (3-panel image)':<75}\")\n    summary_lines.append(f\"{'üìà metrics.csv':<25} {'Training metrics over iterations (CSV format)':<75}\")\n    summary_lines.append(f\"{'üìâ metrics_plot.png':<25} {'Training metrics visualization (6-panel plot)':<75}\")\n    summary_lines.append(f\"{'üß† model.pt':<25} {'Trained 2D Gaussian model (PyTorch checkpoint)':<75}\")\n    summary_lines.append(f\"{'üñºÔ∏è  rendered.jpg':<25} {'Rendered output from model':<75}\")\n    summary_lines.append(f\"{'üìÅ other/':<25} {'Training logs and additional files':<75}\")\n    summary_lines.append(\"=\" * 100)\n    \n    return \"\\n\".join(summary_lines)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "daxcub0q0gd",
   "source": "def _save_summary_files(output_path, fig, summary_text):\n    \"\"\"Save visualization and summary text to files.\"\"\"\n    # Save visualization\n    summary_img_path = os.path.join(output_path, \"summary.png\")\n    fig.savefig(summary_img_path, dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Save summary text\n    summary_txt_path = os.path.join(output_path, \"summary.txt\")\n    with open(summary_txt_path, 'w') as f:\n        f.write(summary_text)\n    \n    print(summary_text)\n    print()\n    print(f\"üíæ Saved: summary.txt\")\n    print(f\"üíæ Saved: summary.png\")\n    print()\n    print(f\"üìÅ Full path: {output_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0uux4mv6iog",
   "source": "def view_results(output_folder):\n    \"\"\"\n    View and analyze results from a training run.\n    \n    Args:\n        output_folder: Name of folder in output/ (e.g., \"cat-10000-5000-20251027_143052\")\n    \"\"\"\n    results_data = _load_training_results(output_folder)\n    metrics_data = _calculate_quality_metrics(results_data['gt_img'], results_data['render_img'])\n    fig = _create_results_visualization(results_data['gt_img'], results_data['render_img'], \n                                       metrics_data['diff_gray'], metrics_data['mean_diff'])\n    summary_text = _format_summary_text(results_data, metrics_data)\n    _save_summary_files(results_data['output_path'], fig, summary_text)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "u0cmbkm2mpf",
   "source": "def upscale_render(output_folder, render_height):\n    \"\"\"\n    Render at higher resolution using trained model.\n    \n    Args:\n        output_folder: Name of folder in output/ with trained model\n        render_height: Target height in pixels\n    \"\"\"\n    ROOT_WORKSPACE, REPO_DIR, INPUT_DIR, OUTPUT_DIR = get_paths()\n    os.chdir(REPO_DIR)\n    \n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    if not os.path.exists(output_path):\n        raise FileNotFoundError(f\"Output folder not found: {output_path}\")\n    \n    # Parse config\n    parts = output_folder.rsplit(\"-\", 3)\n    base_name = parts[0]\n    num_gaussians = int(parts[1])\n    \n    # Find original input\n    input_files = glob.glob(os.path.join(INPUT_DIR, f\"{base_name}.*\"))\n    if not input_files:\n        raise FileNotFoundError(f\"Original input not found for: {base_name}\")\n    input_filename = os.path.basename(input_files[0])\n    \n    # Ensure input is in media/images/\n    media_input_path = os.path.join(REPO_DIR, \"media\", \"images\", input_filename)\n    if not os.path.exists(media_input_path):\n        shutil.copy2(input_files[0], media_input_path)\n    \n    # Run upscale\n    temp_exp_name = f\"temp/{output_folder}\"\n    cmd = f\"\"\"\n    {sys.executable} main.py \\\n      --input_path=\"images/{input_filename}\" \\\n      --exp_name=\"{temp_exp_name}\" \\\n      --num_gaussians={num_gaussians} \\\n      --quantize \\\n      --eval \\\n      --render_height={render_height} \\\n      --device=\"cuda:0\"\n    \"\"\"\n    \n    print(\"=\" * 80)\n    print(f\"üîç UPSCALE RENDER: {output_folder}\")\n    print(\"=\" * 80)\n    print(f\"Target height: {render_height}px\")\n    print(\"=\" * 80)\n    print()\n    \n    os.system(cmd)\n    \n    # Copy upscaled render\n    result_base = os.path.join(REPO_DIR, \"results\", temp_exp_name)\n    run_dirs = [d for d in os.listdir(result_base) if os.path.isdir(os.path.join(result_base, d))]\n    latest_run = sorted(run_dirs)[-1]\n    eval_dir = os.path.join(result_base, latest_run, \"eval\")\n    \n    if os.path.exists(eval_dir):\n        upscaled_renders = glob.glob(os.path.join(eval_dir, \"render_*.jpg\"))\n        if upscaled_renders:\n            upscaled_name = f\"rendered_{render_height}px.jpg\"\n            shutil.copy2(upscaled_renders[0], os.path.join(output_path, upscaled_name))\n            print()\n            print(\"=\" * 80)\n            print(\"‚úÖ UPSCALE COMPLETE\")\n            print(\"=\" * 80)\n            print(f\"üíæ Saved: {upscaled_name}\")\n            print(f\"üìÅ Location: output/{output_folder}/\")\n            print(\"=\" * 80)\n        else:\n            print(\"‚ö†Ô∏è  Warning: Could not find upscaled render\")\n    else:\n        print(\"‚ö†Ô∏è  Warning: Eval directory not found\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "63wj7p6p8ub",
   "source": "def load_metrics_csv(output_folder):\n    \"\"\"\n    Load training metrics from CSV file.\n    \n    Args:\n        output_folder: Name of folder in output/ with training results\n    \n    Returns:\n        pandas.DataFrame: Training metrics with columns:\n            step, total_loss, l1_loss, l2_loss, ssim_loss, psnr, ssim,\n            num_gaussians, num_bytes, render_time_accum, total_time_accum\n    \"\"\"\n    import pandas as pd\n    \n    _, _, _, OUTPUT_DIR = get_paths()\n    \n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    if not os.path.exists(output_path):\n        raise FileNotFoundError(f\"Output folder not found: {output_path}\")\n    \n    metrics_csv_path = os.path.join(output_path, \"metrics.csv\")\n    if not os.path.exists(metrics_csv_path):\n        raise FileNotFoundError(f\"Metrics CSV not found: {metrics_csv_path}\")\n    \n    # Load CSV\n    df = pd.read_csv(metrics_csv_path)\n    \n    # Convert empty strings to NaN for numeric columns\n    numeric_cols = ['total_loss', 'l1_loss', 'l2_loss', 'ssim_loss']\n    for col in numeric_cols:\n        df[col] = pd.to_numeric(df[col], errors='coerce')\n    \n    return df",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hm4iocs4ru4",
   "source": "def plot_training_metrics(output_folder, save_plot=True, show_plot=True):\n    \"\"\"\n    Plot comprehensive training metrics over iterations.\n    \n    Creates a multi-panel visualization showing:\n    - Loss curves (total and components)\n    - Quality metrics (PSNR, SSIM)\n    - Model growth (size, gaussian count)\n    - Timing information\n    \n    Args:\n        output_folder: Name of folder in output/ with training results\n        save_plot: Save plot as metrics_plot.png (default: True)\n        show_plot: Display plot inline (default: True)\n    \"\"\"\n    import pandas as pd\n    \n    # Load metrics\n    df = load_metrics_csv(output_folder)\n    \n    _, _, _, OUTPUT_DIR = get_paths()\n    output_path = os.path.join(OUTPUT_DIR, output_folder)\n    \n    # Parse config from folder name\n    parts = output_folder.rsplit(\"-\", 3)\n    if len(parts) >= 3:\n        base_name = parts[0]\n        num_gaussians = int(parts[1])\n        max_steps = int(parts[2])\n    else:\n        base_name = output_folder\n        num_gaussians = \"?\"\n        max_steps = \"?\"\n    \n    # Create figure with subplots\n    fig = plt.figure(figsize=(20, 12))\n    gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.25)\n    \n    # Title\n    fig.suptitle(f'Training Metrics: {base_name} (G={num_gaussians}, Steps={max_steps})', \n                 fontsize=16, fontweight='bold', y=0.995)\n    \n    # 1. Loss curves (top left)\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax1.plot(df['step'], df['total_loss'], 'k-', linewidth=2, label='Total Loss')\n    if df['l1_loss'].notna().any():\n        ax1.plot(df['step'], df['l1_loss'], '--', alpha=0.7, label='L1 Loss')\n    if df['l2_loss'].notna().any():\n        ax1.plot(df['step'], df['l2_loss'], '--', alpha=0.7, label='L2 Loss')\n    if df['ssim_loss'].notna().any():\n        ax1.plot(df['step'], df['ssim_loss'], '--', alpha=0.7, label='SSIM Loss')\n    ax1.set_xlabel('Training Step', fontsize=12)\n    ax1.set_ylabel('Loss', fontsize=12)\n    ax1.set_title('Loss Components', fontsize=14, fontweight='bold')\n    ax1.legend(loc='best')\n    ax1.grid(True, alpha=0.3)\n    \n    # 2. PSNR (top right)\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax2.plot(df['step'], df['psnr'], 'b-', linewidth=2)\n    ax2.set_xlabel('Training Step', fontsize=12)\n    ax2.set_ylabel('PSNR (dB)', fontsize=12)\n    ax2.set_title('Peak Signal-to-Noise Ratio', fontsize=14, fontweight='bold')\n    ax2.grid(True, alpha=0.3)\n    # Add final value annotation\n    final_psnr = df['psnr'].iloc[-1]\n    ax2.axhline(y=final_psnr, color='b', linestyle='--', alpha=0.3)\n    ax2.text(0.98, 0.02, f'Final: {final_psnr:.2f} dB', \n             transform=ax2.transAxes, ha='right', va='bottom',\n             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n    \n    # 3. SSIM (middle left)\n    ax3 = fig.add_subplot(gs[1, 0])\n    ax3.plot(df['step'], df['ssim'], 'g-', linewidth=2)\n    ax3.set_xlabel('Training Step', fontsize=12)\n    ax3.set_ylabel('SSIM', fontsize=12)\n    ax3.set_title('Structural Similarity Index', fontsize=14, fontweight='bold')\n    ax3.grid(True, alpha=0.3)\n    # Add final value annotation\n    final_ssim = df['ssim'].iloc[-1]\n    ax3.axhline(y=final_ssim, color='g', linestyle='--', alpha=0.3)\n    ax3.text(0.98, 0.02, f'Final: {final_ssim:.4f}', \n             transform=ax3.transAxes, ha='right', va='bottom',\n             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n    \n    # 4. Model size (middle right)\n    ax4 = fig.add_subplot(gs[1, 1])\n    # Convert bytes to KB\n    df['size_kb'] = df['num_bytes'] / 1024\n    ax4.plot(df['step'], df['size_kb'], 'r-', linewidth=2)\n    ax4.set_xlabel('Training Step', fontsize=12)\n    ax4.set_ylabel('Model Size (KB)', fontsize=12)\n    ax4.set_title('Model Size Growth', fontsize=14, fontweight='bold')\n    ax4.grid(True, alpha=0.3)\n    # Add final value annotation\n    final_size = df['size_kb'].iloc[-1]\n    ax4.text(0.98, 0.98, f'Final: {final_size:.2f} KB', \n             transform=ax4.transAxes, ha='right', va='top',\n             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n    \n    # 5. Gaussian count (bottom left)\n    ax5 = fig.add_subplot(gs[2, 0])\n    ax5.plot(df['step'], df['num_gaussians'], 'm-', linewidth=2)\n    ax5.set_xlabel('Training Step', fontsize=12)\n    ax5.set_ylabel('Number of Gaussians', fontsize=12)\n    ax5.set_title('Gaussian Count', fontsize=14, fontweight='bold')\n    ax5.grid(True, alpha=0.3)\n    # Add final value annotation\n    final_gaussians = df['num_gaussians'].iloc[-1]\n    ax5.text(0.98, 0.98, f'Final: {int(final_gaussians):,}', \n             transform=ax5.transAxes, ha='right', va='top',\n             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n    \n    # 6. Timing (bottom right)\n    ax6 = fig.add_subplot(gs[2, 1])\n    ax6.plot(df['step'], df['total_time_accum'], 'c-', linewidth=2, label='Total Time')\n    ax6.plot(df['step'], df['render_time_accum'], 'orange', linewidth=2, label='Render Time')\n    ax6.set_xlabel('Training Step', fontsize=12)\n    ax6.set_ylabel('Time (seconds)', fontsize=12)\n    ax6.set_title('Accumulated Time', fontsize=14, fontweight='bold')\n    ax6.legend(loc='best')\n    ax6.grid(True, alpha=0.3)\n    # Add final value annotation\n    final_time = df['total_time_accum'].iloc[-1]\n    ax6.text(0.98, 0.02, f'Total: {final_time:.1f}s ({final_time/60:.1f}m)', \n             transform=ax6.transAxes, ha='right', va='bottom',\n             bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n    \n    # Save plot\n    if save_plot:\n        plot_path = os.path.join(output_path, \"metrics_plot.png\")\n        fig.savefig(plot_path, dpi=150, bbox_inches='tight')\n        print(f\"üíæ Saved: metrics_plot.png\")\n    \n    # Show plot\n    if show_plot:\n        plt.show()\n    else:\n        plt.close(fig)\n    \n    if save_plot:\n        print(f\"üìÅ Location: {output_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "iz97jih3zxf",
   "source": "print(\"‚úÖ Functions loaded!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hccvnopc4dh",
   "source": "## Step 11: Configuration\n\nSet your input image and training parameters.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": "# Place your input image in: /workspace/input/\n# Example: /workspace/input/cat.png\n\nINPUT_FILENAME = \"cat.png\"  # Just the filename from input/\n\n# Training parameters - use lists for batch training\n# Single value: GAUSSIANS = [5000]\n# Multiple values: GAUSSIANS = [500, 1000, 2000, 5000, 10000]\nGAUSSIANS = [5000]          # Number of Gaussians (5k-30k recommended)\nSTEPS = [3500]              # Training steps (3k-10k recommended)\nUSE_PROGRESSIVE = True      # Enable progressive optimization (recommended)\n\n# Calculate total training runs\ntotal_runs = len(GAUSSIANS) * len(STEPS)\n\nprint(\"=\" * 80)\nprint(\"CONFIGURATION\")\nprint(\"=\" * 80)\nprint(f\"Input:       {os.path.join(ROOT_WORKSPACE, 'input', INPUT_FILENAME)}\")\nprint(f\"Output:      {os.path.join(ROOT_WORKSPACE, 'output')}/\")\nprint(f\"Gaussians:   {GAUSSIANS}\")\nprint(f\"Steps:       {STEPS}\")\nprint(f\"Progressive: {USE_PROGRESSIVE}\")\nprint(f\"Total runs:  {total_runs} ({'x'.join([str(len(GAUSSIANS)), str(len(STEPS))])} combinations)\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": "## Step 12: Training\n\nTrain the model and save to organized output folder."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": "import itertools\nfrom datetime import datetime\n\n# Generate all combinations\ncombinations = list(itertools.product(GAUSSIANS, STEPS))\ntotal_combinations = len(combinations)\n\nprint(\"=\" * 80)\nprint(f\"BATCH TRAINING: {total_combinations} combination(s)\")\nprint(\"=\" * 80)\nprint()\n\n# Store output folders for later viewing\noutput_folders = []\n\n# Train each combination\nfor idx, (num_gaussians, max_steps) in enumerate(combinations, 1):\n    print(f\"{'‚ïê' * 80}\")\n    print(f\"TRAINING {idx}/{total_combinations}\")\n    print(f\"{'‚ïê' * 80}\")\n    print(f\"Parameters: Gaussians={num_gaussians}, Steps={max_steps}\")\n    print()\n    \n    # Estimate total time\n    est_time_min = max_steps * 0.002\n    est_time_max = max_steps * 0.005\n    \n    # Train\n    start_time = datetime.now()\n    output_folder = train_image_gs(\n        input_filename=INPUT_FILENAME,\n        num_gaussians=num_gaussians,\n        max_steps=max_steps,\n        use_progressive=USE_PROGRESSIVE\n    )\n    end_time = datetime.now()\n    elapsed = (end_time - start_time).total_seconds() / 60\n    \n    output_folders.append(output_folder)\n    \n    print(f\"‚è±Ô∏è  Elapsed time: {elapsed:.2f} minutes\")\n    print(f\"üìÅ Output: {output_folder}\")\n    print()\n\nprint(\"=\" * 80)\nprint(\"‚úÖ ALL TRAINING COMPLETE\")\nprint(\"=\" * 80)\nprint(f\"Total runs:     {total_combinations}\")\nprint(f\"Output folders: {len(output_folders)}\")\nprint()\nprint(\"Output folders list:\")\nfor i, folder in enumerate(output_folders, 1):\n    print(f\"  {i}. {folder}\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": "## Step 13: View Results\n\nDisplay comparison visualization and save summary files."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": "# View results from batch training\n# Options:\n# 1. View all results: set VIEW_ALL = True\n# 2. View specific result: set VIEW_ALL = False and specify VIEW_INDEX\n\nVIEW_ALL = True           # View all results from batch training\nVIEW_INDEX = 0            # Index to view (0-based, used when VIEW_ALL=False)\n\nif VIEW_ALL:\n    print(\"=\" * 80)\n    print(f\"VIEWING ALL RESULTS ({len(output_folders)} total)\")\n    print(\"=\" * 80)\n    print()\n    \n    for idx, folder in enumerate(output_folders, 1):\n        print(f\"\\n{'‚ïê' * 80}\")\n        print(f\"RESULT {idx}/{len(output_folders)}: {folder}\")\n        print(f\"{'‚ïê' * 80}\\n\")\n        view_results(folder)\n        print(\"\\n\")\nelse:\n    if 0 <= VIEW_INDEX < len(output_folders):\n        folder = output_folders[VIEW_INDEX]\n        print(f\"Viewing result {VIEW_INDEX + 1}/{len(output_folders)}: {folder}\\n\")\n        view_results(folder)\n    else:\n        print(f\"‚ùå Error: VIEW_INDEX={VIEW_INDEX} is out of range (0-{len(output_folders)-1})\")\n        print(f\"Available folders:\")\n        for i, folder in enumerate(output_folders):\n            print(f\"  {i}. {folder}\")\n\n# Or manually specify a folder:\n# view_results(\"cat-10000-5000-20251027_143052\")"
  },
  {
   "cell_type": "markdown",
   "id": "54h8394zirp",
   "source": "## Step 13b: Compare Batch Results (Optional)\n\nCompare metrics across all trained models.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "puu5gac7evb",
   "source": "def _collect_batch_metrics(output_folders):\n    \"\"\"Collect metrics from all batch training results.\"\"\"\n    _, _, _, OUTPUT_DIR = get_paths()\n    \n    results = []\n    \n    for folder in output_folders:\n        output_path = os.path.join(OUTPUT_DIR, folder)\n        \n        # Parse config\n        parts = folder.rsplit(\"-\", 3)\n        if len(parts) < 3:\n            continue\n        \n        base_name = parts[0]\n        num_gaussians = int(parts[1])\n        max_steps = int(parts[2])\n        \n        # File paths\n        model_path = os.path.join(output_path, \"model.pt\")\n        rendered_path = os.path.join(output_path, \"rendered.jpg\")\n        gt_path = os.path.join(output_path, \"other\", \"ground_truth.jpg\")\n        \n        if not all([os.path.exists(model_path), os.path.exists(rendered_path), os.path.exists(gt_path)]):\n            continue\n        \n        # Get sizes\n        model_size = os.path.getsize(model_path)\n        gt_size = os.path.getsize(gt_path)\n        \n        # Load images and calculate metrics\n        gt_img = np.array(Image.open(gt_path)).astype(np.float32) / 255.0\n        render_img = np.array(Image.open(rendered_path)).astype(np.float32) / 255.0\n        \n        diff = np.abs(gt_img - render_img)\n        diff_gray = np.mean(diff, axis=2)\n        \n        mean_diff = np.mean(diff_gray)\n        max_diff = np.max(diff_gray)\n        \n        # Calculate compression\n        height, width, channels = gt_img.shape\n        total_pixels = width * height\n        bpp = (model_size * 8) / total_pixels\n        compression_ratio = gt_size / model_size\n        \n        results.append({\n            'folder': folder,\n            'gaussians': num_gaussians,\n            'steps': max_steps,\n            'model_size_kb': model_size / 1024,\n            'compression': compression_ratio,\n            'bpp': bpp,\n            'mean_diff': mean_diff,\n            'max_diff': max_diff\n        })\n    \n    # Sort by gaussians, then steps\n    results.sort(key=lambda x: (x['gaussians'], x['steps']))\n    \n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ygysesid0um",
   "source": "def _print_comparison_table(results):\n    \"\"\"Print comparison table for batch results.\"\"\"\n    print(\"=\" * 120)\n    print(\"BATCH TRAINING COMPARISON\")\n    print(\"=\" * 120)\n    print(f\"{'Gaussians':<12} {'Steps':<8} {'Model Size':<14} {'Compression':<14} {'BPP':<10} {'Mean Diff':<14} {'Max Diff':<14}\")\n    print(\"-\" * 120)\n    \n    for r in results:\n        print(f\"{r['gaussians']:<12} {r['steps']:<8} {r['model_size_kb']:>10.2f} KB  {r['compression']:>10.2f}x  {r['bpp']:>8.4f}  {r['mean_diff']:>10.6f}  {r['max_diff']:>10.6f}\")\n    \n    print(\"=\" * 120)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "lm3i00cpyvh",
   "source": "def _print_highlights(results):\n    \"\"\"Print highlights showing best compression and quality.\"\"\"\n    best_compression = max(results, key=lambda x: x['compression'])\n    best_quality = min(results, key=lambda x: x['mean_diff'])\n    \n    print()\n    print(\"HIGHLIGHTS:\")\n    print(f\"  Best Compression: G={best_compression['gaussians']}, S={best_compression['steps']} -> {best_compression['compression']:.2f}x\")\n    print(f\"  Best Quality:     G={best_quality['gaussians']}, S={best_quality['steps']} -> Mean Diff={best_quality['mean_diff']:.6f}\")\n    print(\"=\" * 120)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "obzwziuqaa",
   "source": "def compare_batch_results(output_folders):\n    \"\"\"Compare metrics across all trained models.\"\"\"\n    results = _collect_batch_metrics(output_folders)\n    \n    if not results:\n        print(\"No results to compare\")\n        return\n    \n    _print_comparison_table(results)\n    _print_highlights(results)\n    \n    return results",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "z6nlgsmages",
   "source": "# Run comparison if we have batch results\nif len(output_folders) > 0:\n    comparison_results = compare_batch_results(output_folders)\nelse:\n    print(\"No batch results available. Run the training cell first.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xklggy0i88",
   "source": "## Step 13c: View Training Metrics (Optional)\n\nPlot detailed training metrics showing loss, quality, and size evolution over iterations.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "s7w5k042lk",
   "source": "# Plot training metrics for batch results\n# Options:\n# 1. Plot all results: set PLOT_ALL = True\n# 2. Plot specific result: set PLOT_ALL = False and specify PLOT_INDEX\n\nPLOT_ALL = True           # Plot all results from batch training\nPLOT_INDEX = 0            # Index to plot (0-based, used when PLOT_ALL=False)\n\nif PLOT_ALL:\n    print(\"=\" * 80)\n    print(f\"PLOTTING METRICS FOR ALL RESULTS ({len(output_folders)} total)\")\n    print(\"=\" * 80)\n    print()\n    \n    for idx, folder in enumerate(output_folders, 1):\n        print(f\"\\n{'‚ïê' * 80}\")\n        print(f\"METRICS {idx}/{len(output_folders)}: {folder}\")\n        print(f\"{'‚ïê' * 80}\\n\")\n        try:\n            plot_training_metrics(folder)\n        except FileNotFoundError as e:\n            print(f\"‚ö†Ô∏è  Warning: {e}\")\n        print(\"\\n\")\nelse:\n    if 0 <= PLOT_INDEX < len(output_folders):\n        folder = output_folders[PLOT_INDEX]\n        print(f\"Plotting metrics {PLOT_INDEX + 1}/{len(output_folders)}: {folder}\\n\")\n        plot_training_metrics(folder)\n    else:\n        print(f\"‚ùå Error: PLOT_INDEX={PLOT_INDEX} is out of range (0-{len(output_folders)-1})\")\n        print(f\"Available folders:\")\n        for i, folder in enumerate(output_folders):\n            print(f\"  {i}. {folder}\")\n\n# Or manually specify a folder:\n# plot_training_metrics(\"cat-10000-5000-20251027_143052\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": "## Step 14: Optional - Upscale Render\n\nRender at higher resolution using the trained model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": "# Example: Render at 2x resolution\n# upscale_render(\n#     output_folder=output_folder,  # or specify manually: \"cat-10000-5000-20251027_143052\"\n#     render_height=1024\n# )"
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Optional: Upscale Render\n",
    "\n",
    "Render at higher resolution using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Render at 2x resolution\n",
    "# upscale_render(\n",
    "#     input_image=INPUT_IMAGE,\n",
    "#     exp_name=EXP_NAME,\n",
    "#     num_gaussians=NUM_GAUSSIANS,\n",
    "#     render_height=1024  # Adjust as needed\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}